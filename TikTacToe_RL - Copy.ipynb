{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RrDbEIfO_Sb",
        "outputId": "948e2a7f-7fa3-4290-9072-4d643f9ba905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the agent...\n",
            "Training complete!\n",
            "\n",
            "Agent chose position 6\n",
            "|   |   |   |\n",
            "|   |   |   |\n",
            "| X |   |   |\n",
            "\n",
            "Your turn! Input move (0-8): 6\n",
            "Invalid square. Try again.\n",
            "\n",
            "Your turn! Input move (0-8): 4\n",
            "\n",
            "Agent chose position 7\n",
            "|   |   |   |\n",
            "|   | O |   |\n",
            "| X | X |   |\n",
            "\n",
            "Your turn! Input move (0-8): 8\n",
            "\n",
            "Agent chose position 0\n",
            "| X |   |   |\n",
            "|   | O |   |\n",
            "| X | X | O |\n",
            "\n",
            "Your turn! Input move (0-8): 3\n",
            "\n",
            "Agent chose position 5\n",
            "| X |   |   |\n",
            "| O | O | X |\n",
            "| X | X | O |\n",
            "\n",
            "Your turn! Input move (0-8): 2\n",
            "\n",
            "Agent chose position 1\n",
            "| X | X | O |\n",
            "| O | O | X |\n",
            "| X | X | O |\n",
            "\n",
            "It's a tie!\n",
            "\n",
            "Would you like to play again? (y/n): 0\n",
            "\n",
            "Thanks for playing!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.board = [\" \" for _ in range(9)]\n",
        "        self.current_winner = None\n",
        "\n",
        "    def print_board(self):\n",
        "        for row in [self.board[i*3:(i+1)*3] for i in range(3)]:\n",
        "            print(\"| \" + \" | \".join(row) + \" |\")\n",
        "\n",
        "    def available_moves(self):\n",
        "        return [i for i, spot in enumerate(self.board) if spot == \" \"]\n",
        "\n",
        "    def empty_squares(self):\n",
        "        return \" \" in self.board\n",
        "\n",
        "    def num_empty_squares(self):\n",
        "        return self.board.count(\" \")\n",
        "\n",
        "    def make_move(self, square, letter):\n",
        "        if self.board[square] == \" \":\n",
        "            self.board[square] = letter\n",
        "            if self.winner(square, letter):\n",
        "                self.current_winner = letter\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def winner(self, square, letter):\n",
        "        # Check row\n",
        "        row_ind = square // 3\n",
        "        row = self.board[row_ind*3: (row_ind + 1)*3]\n",
        "        if all([spot == letter for spot in row]):\n",
        "            return True\n",
        "\n",
        "        # Check column\n",
        "        col_ind = square % 3\n",
        "        column = [self.board[col_ind+i*3] for i in range(3)]\n",
        "        if all([spot == letter for spot in column]):\n",
        "            return True\n",
        "\n",
        "        # Check diagonal\n",
        "        if square % 2 == 0:\n",
        "            diagonal1 = [self.board[i] for i in [0, 4, 8]]\n",
        "            if all([spot == letter for spot in diagonal1]):\n",
        "                return True\n",
        "            diagonal2 = [self.board[i] for i in [2, 4, 6]]\n",
        "            if all([spot == letter for spot in diagonal2]):\n",
        "                return True\n",
        "\n",
        "        return False\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, epsilon=0.1, alpha=0.5, gamma=0.9):\n",
        "        self.q_table = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.epsilon = epsilon  # exploration rate\n",
        "        self.alpha = alpha     # learning rate\n",
        "        self.gamma = gamma     # discount factor\n",
        "\n",
        "    def get_state_key(self, board):\n",
        "        return ''.join(board)\n",
        "\n",
        "    def choose_action(self, game, letter):\n",
        "        state = self.get_state_key(game.board)\n",
        "        if random.random() < self.epsilon:\n",
        "            return random.choice(game.available_moves())\n",
        "\n",
        "        return self.get_best_action(game, state)\n",
        "\n",
        "    def get_best_action(self, game, state):\n",
        "        available_moves = game.available_moves()\n",
        "        if not available_moves:\n",
        "            return None\n",
        "\n",
        "        # Get Q-values for all available actions\n",
        "        q_values = {action: self.q_table[state][action] for action in available_moves}\n",
        "        max_q = max(q_values.values())\n",
        "\n",
        "        # Get all actions that have the maximum Q-value\n",
        "        best_actions = [action for action, q_value in q_values.items() if q_value == max_q]\n",
        "        return random.choice(best_actions)\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        best_next_action = max(self.q_table[next_state].values()) if self.q_table[next_state] else 0\n",
        "        current_q = self.q_table[state][action]\n",
        "        new_q = current_q + self.alpha * (reward + self.gamma * best_next_action - current_q)\n",
        "        self.q_table[state][action] = new_q\n",
        "\n",
        "def train(n_games=10000):\n",
        "    agent = QLearningAgent()\n",
        "\n",
        "    for _ in range(n_games):\n",
        "        game = TicTacToe()\n",
        "        current_player = 'X'\n",
        "\n",
        "        while game.empty_squares():\n",
        "            if current_player == 'X':\n",
        "                # Agent's turn\n",
        "                state = agent.get_state_key(game.board)\n",
        "                action = agent.choose_action(game, current_player)\n",
        "\n",
        "                # Make move\n",
        "                game.make_move(action, current_player)\n",
        "\n",
        "                # Get reward\n",
        "                if game.current_winner == 'X':\n",
        "                    reward = 1\n",
        "                elif game.num_empty_squares() == 0:\n",
        "                    reward = 0.5  # Draw\n",
        "                else:\n",
        "                    reward = 0\n",
        "\n",
        "                # Get new state\n",
        "                new_state = agent.get_state_key(game.board)\n",
        "\n",
        "                # Learn from this move\n",
        "                agent.learn(state, action, reward, new_state)\n",
        "\n",
        "                if game.current_winner:\n",
        "                    break\n",
        "            else:\n",
        "                # Random opponent\n",
        "                square = random.choice(game.available_moves())\n",
        "                game.make_move(square, current_player)\n",
        "                if game.current_winner:\n",
        "                    break\n",
        "\n",
        "            current_player = 'O' if current_player == 'X' else 'X'\n",
        "\n",
        "    return agent\n",
        "\n",
        "def play_against_agent(agent):\n",
        "    game = TicTacToe()\n",
        "    current_player = 'X'  # X will be the agent\n",
        "\n",
        "    while game.empty_squares():\n",
        "        if current_player == 'X':\n",
        "            # Agent's turn\n",
        "            square = agent.choose_action(game, current_player)\n",
        "            print(f\"\\nAgent chose position {square}\")\n",
        "        else:\n",
        "            # Human's turn\n",
        "            game.print_board()\n",
        "            valid_square = False\n",
        "            while not valid_square:\n",
        "                square = input(f\"\\nYour turn! Input move (0-8): \")\n",
        "                try:\n",
        "                    square = int(square)\n",
        "                    if square not in game.available_moves():\n",
        "                        raise ValueError\n",
        "                    valid_square = True\n",
        "                except ValueError:\n",
        "                    print(\"Invalid square. Try again.\")\n",
        "\n",
        "        game.make_move(square, current_player)\n",
        "\n",
        "        if game.current_winner:\n",
        "            game.print_board()\n",
        "            print(f\"\\n{current_player} wins!\")\n",
        "            return\n",
        "\n",
        "        current_player = 'O' if current_player == 'X' else 'X'\n",
        "\n",
        "    game.print_board()\n",
        "    print(\"\\nIt's a tie!\")\n",
        "\n",
        "# Train the agent\n",
        "print(\"Training the agent...\")\n",
        "trained_agent = train(10000)\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# Play against the trained agent\n",
        "while True:\n",
        "    play_against_agent(trained_agent)\n",
        "    play_again = input(\"\\nWould you like to play again? (y/n): \")\n",
        "    if play_again.lower() != 'y':\n",
        "        break\n",
        "\n",
        "print(\"\\nThanks for playing!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
